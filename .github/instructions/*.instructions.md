## Review Goal

Prioritize finding:

1. functional bugs
2. behavior regressions
3. production risks
4. missing or weak tests
5. security and secret-handling issues

Avoid style-only comments unless they hide a bug or maintainability risk.

## Repository Context

- Monorepo with shared core + adapters.
- Shared behavior belongs in `core/`.
- Surface integration belongs in:
  - `adapter-claude/`
  - `adapter-cursor/`
  - `adapter-cloud/`
- Domain config conventions in `Domain/`.

## Critical Architecture Rules

1. Keep adapters thin; do not duplicate core orchestration logic.
2. Preserve capability-first behavior (task-oriented, not vendor/tool hardcoded).
3. Preserve MCP interface-first behavior (provider swap should not require core rewrites).
4. Do not introduce direct coupling that breaks cross-surface parity.

## Wix Enterprise Constraints (Must Validate)

1. CI/npm:
   - `npm ci` must work in enterprise context (registry/auth configured).
   - Do not assume public npm defaults if lockfiles point to internal registry.
2. Secrets:
   - Never commit credentials/tokens.
   - Expect secrets from secure stores or CI secrets.
3. Infra assumptions:
   - Validate usage of Redis/S3/Postgres/OTEL against enterprise availability and fallback/migration plans.

## Review Checklist

### A) Correctness

- Does code do what the change claims?
- Are edge cases and failure paths handled?
- Are retries/timeouts/error mapping reasonable?

### B) Regression Risk

- Could this break existing command flows or adapters?
- Could it change investigation output format unexpectedly?
- Could it alter agent isolation or hypothesis loop guarantees?

### C) Security

- Any secret leakage to logs/files?
- Unsafe webhook validation, auth, or signature checks?
- Unsafe default configs in env/sample files?

### D) Reliability

- Clear behavior when MCP/tool dependencies fail?
- Degraded mode or explicit fail-fast behavior where required?
- Queue/storage/network errors handled deterministically?

### E) Tests

- Are tests added/updated for changed behavior?
- Do tests cover negative/error paths?
- Do cross-surface changes include at least one adapter-level validation?

## Output Format Required

Return findings in this order:

1. **High severity**
2. **Medium severity**
3. **Low severity**
4. **Missing tests**
5. **Open questions / assumptions**

For each finding include:

- file path
- short title
- risk summary (why it matters)
- suggested fix

If no findings: explicitly say **"No critical findings"** and list residual risks.
